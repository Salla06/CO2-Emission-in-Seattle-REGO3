# üéØ R√âSUM√â : Alignement Notebooks ‚Üî Dashboard

## ‚úÖ CE QUI A √âT√â FAIT

### 1. Analyse Compl√®te
- ‚úÖ Analys√© `04_modelisation.ipynb` : 5 mod√®les test√©s (Ridge, Lasso, RF, GB, SVR)
- ‚úÖ Analys√© `05_optimization.ipynb` : optimisations GridSearch et RandomizedSearch
- ‚úÖ Identifi√© le mod√®le final : **RandomForest optimis√© (Mod√®le 2 avec ENERGY STAR)**
- ‚úÖ V√©rifi√© que `pipeline_modele2_best.pkl` est bien charg√© dans le dashboard

### 2. Probl√®mes Identifi√©s
- ‚ùå `prediction_logic.py` refait manuellement le feature engineering
- ‚ùå Risque d'incoh√©rence entre features manuelles et features du pipeline
- ‚ùå Pas d'utilisation directe du pipeline scikit-learn

### 3. Fichiers Cr√©√©s

#### `ANALYSE_MODELES.md`
Rapport d√©taill√© listant :
- Tous les mod√®les test√©s dans les notebooks
- La structure attendue du pipeline
- Les 465 features apr√®s one-hot encoding
- Les hyperparam√®tres √† extraire

#### `scripts/inspect_model.py`  
Script d'inspection pour :
- Afficher la structure du pipeline .pkl
- Lister les hyperparam√®tres optimaux

 V√©rifier les features attendues
- Tester une pr√©diction simple

#### `utils/prediction_logic_v2.py`
Version CORRIG√âE qui :
- ‚úÖ Utilise le pipeline complet
- ‚úÖ Pr√©pare les features brutes (pas de transformation manuelle)
- ‚úÖ Laisse le StandardScaler et le mod√®le g√©rer les transformations
- ‚úÖ G√®re les erreurs avec fallback
- ‚úÖ Extrait les feature importances du RF

---

## ‚è≥ CE QU'IL RESTE √Ä FAIRE

### √âtape 1 : V√©rifier l'installation
```bash
python -m pip list | findstr "scikit joblib pandas numpy"
```

Si manquant :
```bash
python -m pip install joblib scikit-learn pandas numpy
```

### √âtape 2 : Inspecter le Mod√®le
```bash
cd "c:\Users\HP\OneDrive\Bureau\Projet Machine Learning\seattle_dashboard"
python scripts\inspect_model.py
```

**Objectifs :**
- Confirmer que c'est un Pipeline
- Voir les √©tapes (StandardScaler + RandomForestRegressor)
- Extraire les hyperparam√®tres optimaux
- V√©rifier combien de features attendues

### √âtape 3 : Extraire les Hyperparam√®tres du Notebook 5

Ouvrir `notebooks/05_optimization.ipynb` et chercher :
```python
# Autour de la ligne 4610-4650
rf_random_m2.best_params_
# Devrait afficher :
# {
#     'n_estimators': XXX,
#     'max_depth': XXX,
#     'min_samples_split': XXX,
#     'min_samples_leaf': XXX,
#     'max_features': 'XXX'
# }
```

**Documenter ces valeurs dans** `ANALYSE_MODELES.md`

### √âtape 4 : V√©rifier model_features.json

Deux possibilit√©s :

**A) Le fichier existe d√©j√†**
```bash
# V√©rifier son contenu
type utils\model_features.json
```

**B) Le fichier n'existe PAS**
Il faut le cr√©er en extrayant les features du notebook 2 (preprocessing) :
```python
# Dans le notebook 02_processing.ipynb
# Apr√®s le one-hot encoding
X_train_m2.columns.tolist()
# Sauvegarder dans utils/model_features.json
```

### √âtape 5 : Tester la Nouvelle Version

**Test 1 : Comparaison c√¥te √† c√¥te**
```python
# Cr√©er un script de test
from utils.prediction_logic import predict_co2 as predict_old
from utils.prediction_logic_v2 import predict_co2 as predict_new

test_data = {
    'gfa': 50000,
    'year_built': 2010,
    'number_of_floors': 5,
    'energy_star_score': 75,
    'location': {'lat': 47.6097, 'lon': -122.3338},
    'neighborhood': 'Downtown',
    'building_type': 'Office'
}

pred_old = predict_old(test_data)
pred_new = predict_new(test_data)

print(f"Ancienne version : {pred_old} T CO2")
print(f"Nouvelle version : {pred_new} T CO2")
print(f"Diff√©rence : {abs(pred_new - pred_old):.2f} T")
```

**Test 2 : Avec le dashboard**
- Remplacer `prediction_logic.py` par `prediction_logic_v2.py`
- Relancer l'application
- Tester plusieurs pr√©dictions
- V√©rifier qu'il n'y a pas d'erreurs

### √âtape 6 : Mise en Production

Si **prediction_logic_v2.py** fonctionne correctement :

```bash
# Sauvegarder l'ancienne version
move utils\prediction_logic.py utils\prediction_logic_OLD.py

# Activer la nouvelle
move utils\prediction_logic_v2.py utils\prediction_logic.py

# Relancer le dashboard
python app.py
```

### √âtape 7 : Documentation (Optionnel mais Recommand√©)

Cr√©er `docs/MODELE_DOCUMENTATION.md` avec :
- Nom du mod√®le : RandomForest Optimis√©
- Hyperparam√®tres exacts
- M√©triques de performance :
  * R¬≤ CV : [valeur]
  * R¬≤ Test : [valeur]
  * RMSE (log) : [valeur]
  * RMSE (tonnes) : [valeur]
  * MAPE : [valeur]%
- Date d'entra√Ænement
- Nombre de features : 465
- Target transform√©e : log1p(TotalGHGEmissions)

---

## üö® POINTS D'ATTENTION

### 1. Features Cat√©gorielles  
Le pipeline attend probablement les features **APR√àS** one-hot encoding. 

**Deux approches possibles :**

**A) Le pipeline fait le one-hot encoding**
‚Üí Passer les colonnes brutes ('Neighborhood', 'BuildingType', etc.)

**B) Le pipeline attend les features d√©j√† encod√©es**
‚Üí Faire le one-hot encoding dans `_prepare_raw_features()`

**‚Üí Le script `inspect_model.py` r√©v√©lera la bonne approche**

### 2. Valeurs par D√©faut
Certaines features ne sont pas demand√©es √† l'utilisateur :
- `PropertyGFAParking` ‚Üí mis √† 0
- `SteamUse(kBtu)` ‚Üí mis √† 0
- `Electricity(kWh)` ‚Üí estim√© (gfa * 10)
- `NaturalGas(therms)` ‚Üí estim√© (gfa * 0.5)

Ces approximations peuvent affecter la pr√©cision !

### 3. Encodages Statistiques
- `Neighborhood_mean`, `Neighborhood_std`
- `PrimaryPropertyType_mean`, `PrimaryPropertyType_std`

Ces valeurs devraient venir du fichier de statistiques d'entra√Ænement, pas √™tre calcul√©es √† la vol√©e !

**Solution :**  
Cr√©er un fichier `utils/encoding_stats.json` avec les valeurs pr√©-calcul√©es.

---

## üìä R√âSULTAT ATTENDU

Apr√®s correction, la pr√©diction devrait utiliser :
1. ‚úÖ Le mod√®le RandomForest optimis√© avec les VRAIS hyperparam√®tres
2. ‚úÖ Le StandardScaler du pipeline (pas de normalisation manuelle)
3. ‚úÖ Les 465 features correctement construites
4. ‚úÖ Les feature importances du mod√®le r√©el

**Bonus :** Si vous exposez le Mod√®le 1 (sans ENERGY STAR), les utilisateurs pourraient comparer :
- Pr√©diction avec ENERGY STAR connu
- Pr√©diction sans ENERGY STAR (phase de conception)

---

## üéì POUR ALLER PLUS LOIN

### Exposer Plus de Mod√®les
```python
# Dans constants.py
MODEL_1_PATH = os.path.join(MODELS_DIR, 'pipeline_modele1_best.pkl')
MODEL_2_PATH = os.path.join(MODELS_DIR, 'pipeline_modele2_best.pkl')
MODEL_GB_PATH = os.path.join(MODELS_DIR, 'pipeline_m2_gb_optimized.pkl')

# Dans app.py
# Ajouter un s√©lecteur pour choisir le mod√®le
```

### Ajouter les Intervalles de Confiance
Si le RandomForest a `n_estimators`, chaque arbre donne une pr√©diction.
L'√©cart-type des pr√©dictions = intervalle de confiance !

```python
# Dans predict()
predictions = [tree.predict(df) for tree in model.estimators_]
mean_pred = np.mean(predictions)
std_pred = np.std(predictions)

return {
    'prediction': mean_pred,
    'confidence_interval': (mean_pred - 2*std_pred, mean_pred + 2*std_pred)
}
```

---

## ‚úÖ CHECKLIST FINALE

- [ ] Packages install√©s (joblib, scikit-learn, pandas, numpy)
- [ ] Script `inspect_model.py` ex√©cut√© avec succ√®s
- [ ] Hyperparam√®tres document√©s dans `ANALYSE_MODELES.md`
- [ ] `model_features.json` v√©rifi√© ou cr√©√©
- [ ] `prediction_logic_v2.py` test√©
- [ ] Ancienne version sauvegard√©e
- [ ] Nouvelle version activ√©e
- [ ] Dashboard relanc√© et test√©
- [ ] Documentation mise √† jour

---

**Date : 2026-02-01**  
**Auteur : Antigravity (Assistant IA)**  
**Projet : Seattle CO2 Dashboard - Alignement Mod√®les ML**
