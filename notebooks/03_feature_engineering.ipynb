{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGO3 - Notebook 03 : Feature Engineering\n",
    "\n",
    "Ce notebook crée de nouvelles features avancées à partir des variables existantes.\n",
    "\n",
    "## Types de features\n",
    "1. **Ratios** : Division de deux variables (ex: surface par étage)\n",
    "2. **Interactions** : Multiplication de deux variables\n",
    "3. **Temporelles** : Âge du bâtiment, ancienneté\n",
    "4. **Agrégations** : Moyennes par quartier/type (FIT/TRANSFORM)\n",
    "5. **Polynomiales** : Puissances, racines\n",
    "\n",
    "## Inputs\n",
    "* `train_processed.csv` : Données train du notebook 02\n",
    "* `test_processed.csv` : Données test du notebook 02\n",
    "\n",
    "## Outputs\n",
    "* `train_with_features.csv` : Train avec nouvelles features\n",
    "* `test_with_features.csv` : Test avec nouvelles features\n",
    "* `feature_engineering_params.pkl` : Paramètres du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 : Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Ajouter src au path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import module feature_engineering\n",
    "from src.feature_engineering import (\n",
    "    create_ratio_features,\n",
    "    create_interaction_features,\n",
    "    create_temporal_features,\n",
    "    create_polynomial_features,\n",
    "    fit_aggregated_features,\n",
    "    transform_aggregated_features,\n",
    "    print_feature_summary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Année de référence: 2016\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "REFERENCE_YEAR = 2016  # Année du dataset\n",
    "\n",
    "# Chemins\n",
    "processed = Path('../data/processed_data')\n",
    "interim = Path('../data/interim_data')\n",
    "interim.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Année de référence: {REFERENCE_YEAR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Chargement des Données Traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1332, 24)\n",
      "Test: (334, 24)\n",
      "\n",
      "Colonnes: 24\n"
     ]
    }
   ],
   "source": [
    "# Charger les données du notebook 02\n",
    "train_df = pd.read_csv(processed / 'train_processed.csv')\n",
    "test_df = pd.read_csv(processed / 'test_processed.csv')\n",
    "\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "print(f\"\\nColonnes: {train_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_columns = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles:\n",
      "  - OSEBuildingID\n",
      "  - BuildingType\n",
      "  - PrimaryPropertyType\n",
      "  - Address\n",
      "  - Neighborhood\n",
      "  - Latitude\n",
      "  - Longitude\n",
      "  - YearBuilt\n",
      "  - NumberofBuildings\n",
      "  - NumberofFloors\n",
      "  - PropertyGFATotal\n",
      "  - PropertyGFAParking\n",
      "  - PropertyGFABuilding(s)\n",
      "  - ListOfAllPropertyUseTypes\n",
      "  - LargestPropertyUseType\n",
      "  - LargestPropertyUseTypeGFA\n",
      "  - SecondLargestPropertyUseType\n",
      "  - SecondLargestPropertyUseTypeGFA\n",
      "  - ENERGYSTARScore\n",
      "  - SteamUse(kBtu)\n",
      "  - Electricity(kWh)\n",
      "  - NaturalGas(therms)\n",
      "  - TotalGHGEmissions\n",
      "  - TotalGHGEmissions_log\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les colonnes disponibles\n",
    "print(\"Colonnes disponibles:\")\n",
    "for col in train_df.columns[:24]:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Identification des Variables Disponibles\n",
    "\n",
    "Nous identifions les variables numériques qui peuvent être utilisées pour créer des features dérivées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 15\n",
      "Liste :\n",
      "  - OSEBuildingID\n",
      "  - Latitude\n",
      "  - Longitude\n",
      "  - YearBuilt\n",
      "  - NumberofBuildings\n",
      "  - NumberofFloors\n",
      "  - PropertyGFATotal\n",
      "  - PropertyGFAParking\n",
      "  - PropertyGFABuilding(s)\n",
      "  - LargestPropertyUseTypeGFA\n",
      "  - SecondLargestPropertyUseTypeGFA\n",
      "  - ENERGYSTARScore\n",
      "  - SteamUse(kBtu)\n",
      "  - Electricity(kWh)\n",
      "  - NaturalGas(therms)\n"
     ]
    }
   ],
   "source": [
    "# Variables cibles (à exclure du feature engineering)\n",
    "target_vars = ['TotalGHGEmissions', 'TotalGHGEmissions_log']\n",
    "\n",
    "# Variables numériques disponibles\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c not in target_vars]\n",
    "\n",
    "print(f\"Total : {len(numeric_cols)}\")\n",
    "print(f\"Liste :\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 : Features Ratios\n",
    "\n",
    "### Définition\n",
    "Les features ratios combinent deux variables par division pour créer des indicateurs d'efficacité ou de proportion.\n",
    "\n",
    "### Exemples\n",
    "- Surface par étage\n",
    "- Ratio parking / surface totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 4\n",
      "  GFA_per_floor = PropertyGFATotal / NumberofFloors\n",
      "  Parking_ratio = PropertyGFAParking / PropertyGFATotal\n",
      "  Building_ratio = PropertyGFABuilding(s) / PropertyGFATotal\n",
      "  GFA_per_building = PropertyGFATotal / NumberofBuildings\n",
      "\n",
      "Variables sources à supprimer après : 5\n",
      "  ['NumberofBuildings', 'NumberofFloors', 'PropertyGFABuilding(s)', 'PropertyGFAParking', 'PropertyGFATotal']\n"
     ]
    }
   ],
   "source": [
    "# Définir les ratios à créer (ajuster selon colonnes disponibles)\n",
    "ratio_definitions = {}\n",
    "ratio_source_vars = []  # Tracker variables sources\n",
    "\n",
    "# Vérifier disponibilité et créer ratios\n",
    "if 'PropertyGFATotal' in train_df.columns and 'NumberofFloors' in train_df.columns:\n",
    "    ratio_definitions['GFA_per_floor'] = ('PropertyGFATotal', 'NumberofFloors')\n",
    "    ratio_source_vars.extend(['PropertyGFATotal', 'NumberofFloors'])\n",
    "\n",
    "if 'PropertyGFAParking' in train_df.columns and 'PropertyGFATotal' in train_df.columns:\n",
    "    ratio_definitions['Parking_ratio'] = ('PropertyGFAParking', 'PropertyGFATotal')\n",
    "    if 'PropertyGFAParking' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('PropertyGFAParking')\n",
    "    if 'PropertyGFATotal' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('PropertyGFATotal')\n",
    "\n",
    "if 'PropertyGFABuilding(s)' in train_df.columns and 'PropertyGFATotal' in train_df.columns:\n",
    "    ratio_definitions['Building_ratio'] = ('PropertyGFABuilding(s)', 'PropertyGFATotal')\n",
    "    if 'PropertyGFABuilding(s)' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('PropertyGFABuilding(s)')\n",
    "    if 'PropertyGFATotal' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('PropertyGFATotal')\n",
    "\n",
    "if 'PropertyGFATotal' in train_df.columns and 'NumberofBuildings' in train_df.columns:\n",
    "    ratio_definitions['GFA_per_building'] = ('PropertyGFATotal', 'NumberofBuildings')\n",
    "    if 'PropertyGFATotal' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('PropertyGFATotal')\n",
    "    if 'NumberofBuildings' not in ratio_source_vars:\n",
    "        ratio_source_vars.append('NumberofBuildings')\n",
    "\n",
    "print(f\"Total : {len(ratio_definitions)}\")\n",
    "for name, (num, denom) in ratio_definitions.items():\n",
    "    print(f\"  {name} = {num} / {denom}\")\n",
    "\n",
    "print(f\"\\nVariables sources à supprimer après : {len(set(ratio_source_vars))}\")\n",
    "print(f\"  {sorted(set(ratio_source_vars))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratios créés : 4\n"
     ]
    }
   ],
   "source": [
    "# Créer ratios\n",
    "if len(ratio_definitions) > 0:\n",
    "    train_with_ratios = create_ratio_features(train_df, ratio_definitions)\n",
    "    test_with_ratios = create_ratio_features(test_df, ratio_definitions)\n",
    "    print(f\"Ratios créés : {len(ratio_definitions)}\")\n",
    "else:\n",
    "    train_with_ratios = train_df.copy()\n",
    "    test_with_ratios = test_df.copy()\n",
    "    print(\"Aucun ratio créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 : Features Temporelles\n",
    "\n",
    "### Définition\n",
    "Features basées sur le temps : âge des bâtiments, ancienneté.\n",
    "\n",
    "### Features créées\n",
    "- Building_age : Âge en années\n",
    "- Building_age_squared : Âge au carré (relation non-linéaire)\n",
    "- Is_old_building : Indicateur binaire (>50 ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES TEMPORELLES\n",
      "================================================================================\n",
      "Features créées : 3\n",
      "  - Building_age\n",
      "  - Building_age_squared\n",
      "  - Is_old_building\n",
      "Variables sources à supprimer après : 1\n",
      "  ['YearBuilt']\n"
     ]
    }
   ],
   "source": [
    "# Créer temporelles\n",
    "train_with_temporal = create_temporal_features(train_with_ratios, REFERENCE_YEAR)\n",
    "test_with_temporal = create_temporal_features(test_with_ratios, REFERENCE_YEAR)\n",
    "\n",
    "# Identifier sources à supprimer\n",
    "temporal_source_vars = []\n",
    "if 'Building_age' in train_with_temporal.columns:\n",
    "    # On garde Building_age de base, on supprime YearBuilt\n",
    "    if 'YearBuilt' in train_with_temporal.columns:\n",
    "        temporal_source_vars.append('YearBuilt')\n",
    "    # Si on a Building_age_squared, pas besoin de supprimer Building_age (info complémentaire)\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES TEMPORELLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "temporal_created = [c for c in ['Building_age', 'Building_age_squared', 'Is_old_building'] if c in train_with_temporal.columns]\n",
    "print(f\"Features créées : {len(temporal_created)}\")\n",
    "for feat in temporal_created:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"Variables sources à supprimer après : {len(temporal_source_vars)}\")\n",
    "if temporal_source_vars:\n",
    "    print(f\"  {temporal_source_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution de l'âge des bâtiments:\n",
      "count    1332.000000\n",
      "mean       54.280030\n",
      "std        32.386756\n",
      "min         7.000000\n",
      "25%        27.000000\n",
      "50%        51.000000\n",
      "75%        86.000000\n",
      "max       110.000000\n",
      "Name: Building_age, dtype: float64\n",
      "\n",
      "Bâtiments anciens (>50 ans): 677\n"
     ]
    }
   ],
   "source": [
    "# Vérifier la distribution de l'âge\n",
    "if 'Building_age' in train_with_temporal.columns:\n",
    "    print(\"Distribution de l'âge des bâtiments:\")\n",
    "    print(train_with_temporal['Building_age'].describe())\n",
    "    print(f\"\\nBâtiments anciens (>50 ans): {train_with_temporal['Is_old_building'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 : Features Interactions\n",
    "\n",
    "### Définition\n",
    "Multiplication de deux variables pour capturer leurs effets combinés.\n",
    "\n",
    "### Exemples\n",
    "- Size × Floors : Volume approximatif\n",
    "- Age × Size : Vieux grands bâtiments vs nouveaux petits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES INTERACTIONS\n",
      "================================================================================\n",
      "\n",
      "Interactions à créer : 3\n",
      "  Size_floors = PropertyGFATotal × NumberofFloors\n",
      "  Age_size = Building_age × PropertyGFATotal\n",
      "  Age_floors = Building_age × NumberofFloors\n",
      "\n",
      "Variables sources à supprimer après : 3\n",
      "  ['Building_age', 'NumberofFloors', 'PropertyGFATotal']\n"
     ]
    }
   ],
   "source": [
    "# Définir interactions\n",
    "interaction_definitions = {}\n",
    "interaction_source_vars = []\n",
    "\n",
    "if 'PropertyGFATotal' in train_with_temporal.columns and 'NumberofFloors' in train_with_temporal.columns:\n",
    "    interaction_definitions['Size_floors'] = ('PropertyGFATotal', 'NumberofFloors')\n",
    "    if 'PropertyGFATotal' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('PropertyGFATotal')\n",
    "    if 'NumberofFloors' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('NumberofFloors')\n",
    "\n",
    "if 'Building_age' in train_with_temporal.columns and 'PropertyGFATotal' in train_with_temporal.columns:\n",
    "    interaction_definitions['Age_size'] = ('Building_age', 'PropertyGFATotal')\n",
    "    if 'Building_age' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('Building_age')\n",
    "    if 'PropertyGFATotal' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('PropertyGFATotal')\n",
    "\n",
    "if 'Building_age' in train_with_temporal.columns and 'NumberofFloors' in train_with_temporal.columns:\n",
    "    interaction_definitions['Age_floors'] = ('Building_age', 'NumberofFloors')\n",
    "    if 'Building_age' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('Building_age')\n",
    "    if 'NumberofFloors' not in interaction_source_vars:\n",
    "        interaction_source_vars.append('NumberofFloors')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES INTERACTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInteractions à créer : {len(interaction_definitions)}\")\n",
    "for name, (var1, var2) in interaction_definitions.items():\n",
    "    print(f\"  {name} = {var1} × {var2}\")\n",
    "\n",
    "print(f\"\\nVariables sources à supprimer après : {len(set(interaction_source_vars))}\")\n",
    "print(f\"  {sorted(set(interaction_source_vars))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions créées : 3\n"
     ]
    }
   ],
   "source": [
    "# Créer interactions\n",
    "if len(interaction_definitions) > 0:\n",
    "    train_with_inter = create_interaction_features(train_with_temporal, interaction_definitions)\n",
    "    test_with_inter = create_interaction_features(test_with_temporal, interaction_definitions)\n",
    "    print(f\"Interactions créées : {len(interaction_definitions)}\")\n",
    "else:\n",
    "    train_with_inter = train_with_temporal.copy()\n",
    "    test_with_inter = test_with_temporal.copy()\n",
    "    print(\"Aucune interaction créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6 : Features Polynomiales\n",
    "\n",
    "### Définition\n",
    "Puissances et racines de variables pour capturer des relations non-linéaires.\n",
    "\n",
    "### Exemples\n",
    "- Surface² : Effet quadratique\n",
    "- √Surface : Effet atténué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES POLYNOMIALES\n",
      "================================================================================\n",
      "\n",
      "Polynômes à créer : 3\n",
      "  GFA_squared = PropertyGFATotal^2\n",
      "  GFA_sqrt = PropertyGFATotal^0.5\n",
      "  Floors_squared = NumberofFloors^2\n",
      "\n",
      "Variables sources à supprimer après : 2\n",
      "  ['NumberofFloors', 'PropertyGFATotal']\n"
     ]
    }
   ],
   "source": [
    "# Définir polynômes\n",
    "polynomial_definitions = {}\n",
    "polynomial_source_vars = []\n",
    "\n",
    "if 'PropertyGFATotal' in train_with_inter.columns:\n",
    "    polynomial_definitions['GFA_squared'] = ('PropertyGFATotal', 2)\n",
    "    polynomial_definitions['GFA_sqrt'] = ('PropertyGFATotal', 0.5)\n",
    "    if 'PropertyGFATotal' not in polynomial_source_vars:\n",
    "        polynomial_source_vars.append('PropertyGFATotal')\n",
    "\n",
    "if 'NumberofFloors' in train_with_inter.columns:\n",
    "    polynomial_definitions['Floors_squared'] = ('NumberofFloors', 2)\n",
    "    if 'NumberofFloors' not in polynomial_source_vars:\n",
    "        polynomial_source_vars.append('NumberofFloors')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES POLYNOMIALES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPolynômes à créer : {len(polynomial_definitions)}\")\n",
    "for name, (var, power) in polynomial_definitions.items():\n",
    "    print(f\"  {name} = {var}^{power}\")\n",
    "\n",
    "print(f\"\\nVariables sources à supprimer après : {len(set(polynomial_source_vars))}\")\n",
    "print(f\"  {sorted(set(polynomial_source_vars))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynômes créés : 3\n"
     ]
    }
   ],
   "source": [
    "# Créer polynômes\n",
    "if len(polynomial_definitions) > 0:\n",
    "    train_with_poly = create_polynomial_features(train_with_inter, polynomial_definitions)\n",
    "    test_with_poly = create_polynomial_features(test_with_inter, polynomial_definitions)\n",
    "    print(f\"\\nPolynômes créés : {len(polynomial_definitions)}\")\n",
    "else:\n",
    "    train_with_poly = train_with_inter.copy()\n",
    "    test_with_poly = test_with_inter.copy()\n",
    "    print(\"\\nAucun polynôme créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7 : Features Agrégées (FIT/TRANSFORM)\n",
    "\n",
    "### Définition\n",
    "Statistiques par groupe (quartier, type de propriété, etc.).\n",
    "\n",
    "### IMPORTANT\n",
    "Ces features utilisent la variable cible, donc :\n",
    "- **FIT** : Calculer statistiques sur TRAIN uniquement\n",
    "- **TRANSFORM** : Appliquer ces statistiques sur TRAIN et TEST\n",
    "\n",
    "### Exemples\n",
    "- Émission moyenne par quartier\n",
    "- Émission médiane par type de propriété"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURES AGRÉGÉES\n",
      "================================================================================\n",
      "\n",
      "Colonnes de groupement disponibles : 2\n",
      "  - Neighborhood\n",
      "  - PrimaryPropertyType\n",
      "\n",
      "Ces colonnes seront CONSERVÉES (info complémentaire aux agrégations)\n"
     ]
    }
   ],
   "source": [
    "# Identifier colonnes de groupement\n",
    "possible_groupby = ['Neighborhood', 'PrimaryPropertyType', 'ZipCode']\n",
    "available_groupby = [col for col in possible_groupby if col in train_with_poly.columns]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURES AGRÉGÉES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nColonnes de groupement disponibles : {len(available_groupby)}\")\n",
    "for col in available_groupby:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Note : On GARDE les variables de groupement (info différente des agrégations)\n",
    "print(f\"\\nCes colonnes seront CONSERVÉES (info complémentaire aux agrégations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features agrégées créées : 6\n"
     ]
    }
   ],
   "source": [
    "# FIT et TRANSFORM\n",
    "if len(available_groupby) > 0 and 'TotalGHGEmissions_log' in train_with_poly.columns:\n",
    "    agg_params = fit_aggregated_features(\n",
    "        train_with_poly,\n",
    "        target_col='TotalGHGEmissions_log',\n",
    "        groupby_cols=available_groupby,\n",
    "        agg_functions=['mean', 'median', 'std']\n",
    "    )\n",
    "    \n",
    "    train_with_agg = transform_aggregated_features(train_with_poly, agg_params)\n",
    "    test_with_agg = transform_aggregated_features(test_with_poly, agg_params)\n",
    "    \n",
    "    n_agg = len(available_groupby) * len(agg_params['agg_functions'])\n",
    "    print(f\"\\nFeatures agrégées créées : {n_agg}\")\n",
    "else:\n",
    "    agg_params = None\n",
    "    train_with_agg = train_with_poly.copy()\n",
    "    test_with_agg = test_with_poly.copy()\n",
    "    print(\"\\nAucune feature agrégée créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7 : Suppression Variables Sources\n",
    "\n",
    "### Principe\n",
    "Supprimer les variables sources des features dérivées pour éviter multicolinéarité.\n",
    "\n",
    "### Règles appliquées\n",
    "- Ratios : Supprimer les 2 sources\n",
    "- Interactions : Supprimer les 2 sources\n",
    "- Polynômes : Supprimer la source\n",
    "- Temporelles : Supprimer YearBuilt (garder Building_age)\n",
    "- Agrégées : Garder les variables de groupement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUPPRESSION VARIABLES SOURCES\n",
      "================================================================================\n",
      "\n",
      "Variables sources identifiées : 7\n",
      "Variables à supprimer : 7\n",
      "\n",
      "Liste :\n",
      "  - Building_age\n",
      "  - NumberofBuildings\n",
      "  - NumberofFloors\n",
      "  - PropertyGFABuilding(s)\n",
      "  - PropertyGFAParking\n",
      "  - PropertyGFATotal\n",
      "  - YearBuilt\n"
     ]
    }
   ],
   "source": [
    "# Consolider toutes les variables sources à supprimer\n",
    "all_source_vars = set()\n",
    "all_source_vars.update(ratio_source_vars)\n",
    "all_source_vars.update(temporal_source_vars)\n",
    "all_source_vars.update(interaction_source_vars)\n",
    "all_source_vars.update(polynomial_source_vars)\n",
    "\n",
    "# Filtrer celles qui existent dans le dataset\n",
    "vars_to_drop = [v for v in all_source_vars if v in train_with_agg.columns]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUPPRESSION VARIABLES SOURCES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nVariables sources identifiées : {len(all_source_vars)}\")\n",
    "print(f\"Variables à supprimer : {len(vars_to_drop)}\")\n",
    "print(f\"\\nListe :\")\n",
    "for var in sorted(vars_to_drop):\n",
    "    print(f\"  - {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suppression effectuée\n",
      "  Avant : (1332, 43)\n",
      "  Après : (1332, 36)\n",
      "  Colonnes supprimées : 7\n"
     ]
    }
   ],
   "source": [
    "# Supprimer\n",
    "if len(vars_to_drop) > 0:\n",
    "    train_clean = train_with_agg.drop(columns=vars_to_drop)\n",
    "    test_clean = test_with_agg.drop(columns=vars_to_drop)\n",
    "    \n",
    "    print(f\"\\nSuppression effectuée\")\n",
    "    print(f\"  Avant : {train_with_agg.shape}\")\n",
    "    print(f\"  Après : {train_clean.shape}\")\n",
    "    print(f\"  Colonnes supprimées : {len(vars_to_drop)}\")\n",
    "else:\n",
    "    train_clean = train_with_agg.copy()\n",
    "    test_clean = test_with_agg.copy()\n",
    "    print(f\"\\nAucune variable à supprimer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8 : Vérification Multicolinéarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VÉRIFICATION MULTICOLINÉARITÉ\n",
      "================================================================================\n",
      "\n",
      "Paires avec corrélation > 0.9 : 9\n",
      "\n",
      "ATTENTION : Corrélations élevées détectées\n",
      "  LargestPropertyUseTypeGFA <-> GFA_per_building : 0.954\n",
      "  LargestPropertyUseTypeGFA <-> GFA_squared : 0.927\n",
      "  LargestPropertyUseTypeGFA <-> GFA_sqrt : 0.938\n",
      "  Parking_ratio <-> Building_ratio : 0.939\n",
      "  GFA_per_building <-> GFA_squared : 0.967\n",
      "  GFA_per_building <-> GFA_sqrt : 0.983\n",
      "  GFA_squared <-> GFA_sqrt : 0.906\n",
      "  Neighborhood_mean <-> Neighborhood_median : 0.978\n",
      "  PrimaryPropertyType_mean <-> PrimaryPropertyType_median : 0.989\n"
     ]
    }
   ],
   "source": [
    "# Calculer matrice de corrélation sur variables numériques\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns\n",
    "target_vars = ['TotalGHGEmissions', 'TotalGHGEmissions_log']\n",
    "numeric_features = [c for c in numeric_cols if c not in target_vars]\n",
    "\n",
    "if len(numeric_features) > 0:\n",
    "    corr_matrix = train_clean[numeric_features].corr().abs()\n",
    "    \n",
    "    # Identifier paires haute corrélation (>0.9)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if corr_matrix.iloc[i, j] > 0.9:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i],\n",
    "                    corr_matrix.columns[j],\n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"VÉRIFICATION MULTICOLINÉARITÉ\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nPaires avec corrélation > 0.9 : {len(high_corr_pairs)}\")\n",
    "    \n",
    "    if len(high_corr_pairs) > 0:\n",
    "        print(f\"\\nATTENTION : Corrélations élevées détectées\")\n",
    "        for var1, var2, corr in high_corr_pairs[:10]:  # Afficher max 10\n",
    "            print(f\"  {var1} <-> {var2} : {corr:.3f}\")\n",
    "        if len(high_corr_pairs) > 10:\n",
    "            print(f\"  ... et {len(high_corr_pairs) - 10} autres paires\")\n",
    "    else:\n",
    "        print(f\"\\nOK : Pas de corrélation excessive (>0.9)\")\n",
    "else:\n",
    "    print(\"Pas de variables numériques à vérifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUPPRESSION VARIABLES REDONDANTES (MULTICOLINÉARITÉ)\n",
      "================================================================================\n",
      " GFA_squared (redondant avec GFA_sqrt)\n",
      " GFA_per_building (redondant avec GFA_sqrt)\n",
      " Building_ratio (redondant avec Parking_ratio)\n",
      " Neighborhood_median (redondant avec _mean)\n",
      " PrimaryPropertyType_median (redondant avec _mean)\n",
      "\n",
      "Total variables à supprimer : 5\n",
      "\n",
      "Après nettoyage multicolinéarité :\n",
      "  Train : (1332, 31)\n",
      "  Test : (334, 31)\n"
     ]
    }
   ],
   "source": [
    "# Section 8 : Suppression des variables redondantes\n",
    "print(\"=\"*80)\n",
    "print(\"SUPPRESSION VARIABLES REDONDANTES (MULTICOLINÉARITÉ)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vars_to_drop_multicollinearity = []\n",
    "\n",
    "# 1. Garder seulement GFA_sqrt (éliminer GFA_squared et GFA_per_building)\n",
    "if 'GFA_squared' in train_clean.columns:\n",
    "    vars_to_drop_multicollinearity.append('GFA_squared')\n",
    "    print(\" GFA_squared (redondant avec GFA_sqrt)\")\n",
    "\n",
    "if 'GFA_per_building' in train_clean.columns:\n",
    "    vars_to_drop_multicollinearity.append('GFA_per_building')\n",
    "    print(\" GFA_per_building (redondant avec GFA_sqrt)\")\n",
    "\n",
    "# 2. Garder seulement Parking_ratio (éliminer Building_ratio)\n",
    "if 'Building_ratio' in train_clean.columns:\n",
    "    vars_to_drop_multicollinearity.append('Building_ratio')\n",
    "    print(\" Building_ratio (redondant avec Parking_ratio)\")\n",
    "\n",
    "# 3. Garder seulement mean pour les agrégations (éliminer median)\n",
    "for col in train_clean.columns:\n",
    "    if '_median' in col:\n",
    "        vars_to_drop_multicollinearity.append(col)\n",
    "        print(f\" {col} (redondant avec _mean)\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nTotal variables à supprimer : {len(vars_to_drop_multicollinearity)}\")\n",
    "\n",
    "# Appliquer la suppression\n",
    "train_clean = train_clean.drop(columns=vars_to_drop_multicollinearity)\n",
    "test_clean = test_clean.drop(columns=vars_to_drop_multicollinearity)\n",
    "\n",
    "print(f\"\\nAprès nettoyage multicolinéarité :\")\n",
    "print(f\"  Train : {train_clean.shape}\")\n",
    "print(f\"  Test : {test_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VÉRIFICATION POST-NETTOYAGE\n",
      "================================================================================\n",
      "Paires avec corrélation > 0.9 : 1\n",
      "  LargestPropertyUseTypeGFA <-> GFA_sqrt : 0.938\n"
     ]
    }
   ],
   "source": [
    "# Vérifier qu'il n'y a plus de corrélations > 0.9\n",
    "numeric_cols = train_clean.select_dtypes(include=[np.number]).columns\n",
    "target_vars = ['TotalGHGEmissions', 'TotalGHGEmissions_log']\n",
    "numeric_features = [c for c in numeric_cols if c not in target_vars]\n",
    "\n",
    "corr_matrix = train_clean[numeric_features].corr().abs()\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.9:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VÉRIFICATION POST-NETTOYAGE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Paires avec corrélation > 0.9 : {len(high_corr_pairs)}\")\n",
    "\n",
    "if len(high_corr_pairs) > 0:\n",
    "    for var1, var2, corr in high_corr_pairs:\n",
    "        print(f\"  {var1} <-> {var2} : {corr:.3f}\")\n",
    "else:\n",
    "    print(\"cOK : Pas de multicolinéarité excessive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9 : Nettoyage Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NETTOYAGE FINAL\n",
      "================================================================================\n",
      "\n",
      "Avant nettoyage :\n",
      "  NA train : 0\n",
      "  NA test : 0\n",
      "  Inf train : 0\n",
      "  Inf test : 0\n",
      "\n",
      "Aucun nettoyage nécessaire\n"
     ]
    }
   ],
   "source": [
    "# Traiter NA et Inf créés\n",
    "na_train = train_clean.isnull().sum().sum()\n",
    "na_test = test_clean.isnull().sum().sum()\n",
    "inf_train = np.isinf(train_clean.select_dtypes(include=[np.number])).sum().sum()\n",
    "inf_test = np.isinf(test_clean.select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NETTOYAGE FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAvant nettoyage :\")\n",
    "print(f\"  NA train : {na_train}\")\n",
    "print(f\"  NA test : {na_test}\")\n",
    "print(f\"  Inf train : {inf_train}\")\n",
    "print(f\"  Inf test : {inf_test}\")\n",
    "\n",
    "if na_train > 0 or na_test > 0 or inf_train > 0 or inf_test > 0:\n",
    "    # Identifier nouvelles colonnes\n",
    "    new_cols = [c for c in train_clean.columns if c not in initial_columns]\n",
    "    \n",
    "    # Remplacer Inf par NaN puis NaN par 0\n",
    "    for col in new_cols:\n",
    "        if col in train_clean.columns:\n",
    "            train_clean[col] = train_clean[col].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "            test_clean[col] = test_clean[col].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    print(f\"\\nAprès nettoyage :\")\n",
    "    print(f\"  NA train : {train_clean.isnull().sum().sum()}\")\n",
    "    print(f\"  NA test : {test_clean.isnull().sum().sum()}\")\n",
    "    print(f\"  Inf train : {np.isinf(train_clean.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "    print(f\"  Inf test : {np.isinf(test_clean.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "else:\n",
    "    print(f\"\\nAucun nettoyage nécessaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10 : Résumé et Vérifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RÉSUMÉ FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "Features créées : 19\n",
      "  Ratios : 4\n",
      "  Temporelles : 3\n",
      "  Interactions : 3\n",
      "  Polynomiales : 3\n",
      "  Agrégées : 6\n",
      "\n",
      "Variables sources supprimées : 7\n",
      "\n",
      "Bilan : +19 créées, -7 supprimées = 12 nettes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RÉSUMÉ FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Détail\n",
    "n_created = len(ratio_definitions) + len(temporal_created) + len(interaction_definitions) + len(polynomial_definitions)\n",
    "if agg_params:\n",
    "    n_created += len(available_groupby) * len(agg_params['agg_functions'])\n",
    "\n",
    "print(f\"\\nFeatures créées : {n_created}\")\n",
    "print(f\"  Ratios : {len(ratio_definitions)}\")\n",
    "print(f\"  Temporelles : {len(temporal_created)}\")\n",
    "print(f\"  Interactions : {len(interaction_definitions)}\")\n",
    "print(f\"  Polynomiales : {len(polynomial_definitions)}\")\n",
    "if agg_params:\n",
    "    print(f\"  Agrégées : {len(available_groupby) * len(agg_params['agg_functions'])}\")\n",
    "\n",
    "print(f\"\\nVariables sources supprimées : {len(vars_to_drop)}\")\n",
    "\n",
    "print(f\"\\nBilan : +{n_created} créées, -{len(vars_to_drop)} supprimées = {n_created - len(vars_to_drop)} nettes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VÉRIFICATIONS FINALES\n",
      "================================================================================\n",
      "\n",
      "1. Même nb colonnes train/test : True\n",
      "2. Pas de NA train : True\n",
      "3. Pas de NA test : True\n",
      "4. Pas de Inf train : True\n",
      "5. Pas de Inf test : True\n",
      "\n",
      "Statut global : OK\n"
     ]
    }
   ],
   "source": [
    "# Vérifications finales\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VÉRIFICATIONS FINALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "check1 = train_clean.shape[1] == test_clean.shape[1]\n",
    "check2 = train_clean.isnull().sum().sum() == 0\n",
    "check3 = test_clean.isnull().sum().sum() == 0\n",
    "check4 = np.isinf(train_clean.select_dtypes(include=[np.number])).sum().sum() == 0\n",
    "check5 = np.isinf(test_clean.select_dtypes(include=[np.number])).sum().sum() == 0\n",
    "\n",
    "print(f\"\\n1. Même nb colonnes train/test : {check1}\")\n",
    "print(f\"2. Pas de NA train : {check2}\")\n",
    "print(f\"3. Pas de NA test : {check3}\")\n",
    "print(f\"4. Pas de Inf train : {check4}\")\n",
    "print(f\"5. Pas de Inf test : {check5}\")\n",
    "\n",
    "all_ok = all([check1, check2, check3, check4, check5])\n",
    "print(f\"\\nStatut global : {'OK' if all_ok else 'PROBLÈME DÉTECTÉ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11 : Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_with_features.csv : (1332, 31)\n",
      "test_with_features.csv : (334, 31)\n",
      "\n",
      "Localisation : ..\\data\\interim_data\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder datasets\n",
    "train_clean.to_csv(interim / 'train_with_features.csv', index=False)\n",
    "test_clean.to_csv(interim / 'test_with_features.csv', index=False)\n",
    "\n",
    "print(f\"\\ntrain_with_features.csv : {train_clean.shape}\")\n",
    "print(f\"test_with_features.csv : {test_clean.shape}\")\n",
    "print(f\"\\nLocalisation : {interim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PARAMÈTRES SAUVEGARDÉS\n",
      "feature_engineering_params.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder paramètres\n",
    "feature_params = {\n",
    "    'ratio_definitions': ratio_definitions,\n",
    "    'interaction_definitions': interaction_definitions,\n",
    "    'polynomial_definitions': polynomial_definitions,\n",
    "    'aggregated_features': agg_params if agg_params else {},\n",
    "    'reference_year': REFERENCE_YEAR,\n",
    "    'n_features_initial': len(initial_columns),\n",
    "    'n_features_final': len(train_clean.columns),\n",
    "    'n_features_created': n_created,\n",
    "    'n_features_dropped': len(vars_to_drop),\n",
    "    'dropped_source_vars': sorted(vars_to_drop),\n",
    "    'high_corr_pairs': len(high_corr_pairs) if 'high_corr_pairs' in locals() else 0\n",
    "}\n",
    "\n",
    "joblib.dump(feature_params, interim / 'feature_engineering_params.pkl')\n",
    "\n",
    "print(\"\\nPARAMÈTRES SAUVEGARDÉS\")\n",
    "print(f\"feature_engineering_params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE ENGINEERING TERMINÉ\n",
      "================================================================================\n",
      "Prochaine étape : Feature Selection (Notebook 04)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING TERMINÉ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Prochaine étape : Feature Selection (Notebook 04)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
